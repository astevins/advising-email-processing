{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be90a936-0105-4761-9272-7f460f655c57",
   "metadata": {},
   "source": [
    "## Trains a transformers model to extract the relevant content of emails\n",
    "Recommended setup:\n",
    "- AWS SageMaker Studio\n",
    "- Image: Pytorch 2.0.0 Python 3.10 GPU Optimized\n",
    "- Instance Type: g4dn.xlarge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177576b4-bc78-4906-9e1d-c6485277afcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers[torch] datasets evaluate huggingface_hub sentencepiece seqeval accelerate ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d54f76-fe04-4004-9466-e3dbb98fa555",
   "metadata": {},
   "source": [
    "### Load models and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ae51c-cb2d-427c-aa1e-c4e4873f7898",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import ast\n",
    "from transformers import AutoTokenizer, DataCollatorForTokenClassification\n",
    "from datasets import Dataset, DatasetDict\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40921c26-de9d-44bc-91c3-075f5a1779a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "ENCODING = config['global']['ENCODING']\n",
    "\n",
    "model_checkpoint = \"roberta-base\"\n",
    "max_length = 512\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa45ac80-bcca-46b0-b5fd-11f3620ac564",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load annotated data from file\n",
    "\n",
    "training_data_file = config['extract_contents']['TRAINING_ANNOTATION_FILE']\n",
    "cols = {\n",
    "    'from': 9,\n",
    "    'body': 4,\n",
    "    'question': 13,\n",
    "    'answer': 3,\n",
    "}\n",
    "\n",
    "q_docs = {\"text\": [], \"target\": []}\n",
    "a_docs = {\"text\": [], \"target\": []}\n",
    "\n",
    "def read_csv():\n",
    "    with open(training_data_file, 'r', encoding=ENCODING) as csvfile:\n",
    "        datareader = csv.reader(csvfile)\n",
    "        next(datareader) # skip header row \n",
    "        \n",
    "        for row in datareader:\n",
    "            if len(row) == 0: continue\n",
    "            \n",
    "            is_q = row[cols['from']] == '1'\n",
    "            is_a = row[cols['from']] == '2'\n",
    "            \n",
    "            if not is_q and not is_a: continue\n",
    "            \n",
    "            spans = row[cols['question'] if is_q else cols['answer']]\n",
    "            data_list = q_docs if is_q else a_docs\n",
    "            \n",
    "            data_list[\"text\"].append(row[cols['body']])\n",
    "            \n",
    "            target = None\n",
    "            if spans:\n",
    "                span = ast.literal_eval(spans)[0]\n",
    "                data_list[\"target\"].append({\"start\": span[\"start\"], \"end\": span[\"end\"]})\n",
    "            else:\n",
    "                data_list[\"target\"].append({\"start\": 0, \"end\": 0})\n",
    "\n",
    "def make_dataset_split(docs, test_size=0.15, valid_size=0.15):\n",
    "    \"\"\"\n",
    "    Creates a dataset with train/test/valid split\n",
    "    \"\"\"\n",
    "    dataset = Dataset.from_dict(docs)\n",
    "    train_testvalid = dataset.train_test_split(test_size = test_size + valid_size)\n",
    "    test_valid = train_testvalid['test'].train_test_split(test_size = test_size / (test_size + valid_size))\n",
    "\n",
    "    dataset = DatasetDict({\n",
    "        'train': train_testvalid['train'],\n",
    "        'test': test_valid['test'],\n",
    "        'valid': test_valid['train']})\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ad148-3748-4152-8af4-b773bf1d613b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the data as expected for the training function\n",
    "\n",
    "label_names = [\n",
    "    \"I-E\",\n",
    "    \"O\"\n",
    "]\n",
    "\n",
    "label2id = {\n",
    "    \"I-E\": 0,\n",
    "    \"O\": 1\n",
    "}\n",
    "\n",
    "id2label = {\n",
    "    0: \"I-E\",\n",
    "    1: \"O\"\n",
    "}\n",
    "\n",
    "def tokenize(examples):\n",
    "    return tokenizer(examples, truncation=True, is_split_into_words=False, return_overflowing_tokens=True, \n",
    "                     return_offsets_mapping=True, max_length = max_length, stride = 128, padding=\"max_length\")\n",
    "\n",
    "def preprocess(examples):\n",
    "    tokenized_inputs = tokenize(examples[\"text\"])\n",
    "\n",
    "    overflow_to_sample_mapping = tokenized_inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    offsets_mapping = tokenized_inputs.pop(\"offset_mapping\")\n",
    "    targets = examples[\"target\"]\n",
    "\n",
    "    labels = []\n",
    "    sample_ids = []\n",
    "    for i, offset_mapping in enumerate(offsets_mapping):\n",
    "        sample_ids.append(overflow_to_sample_mapping[i])\n",
    "        target = targets[overflow_to_sample_mapping[i]]\n",
    "        start_char = target[\"start\"]\n",
    "        end_char = target[\"end\"] + 1\n",
    "        \n",
    "        label = []\n",
    "        for token_mapping in offset_mapping:\n",
    "            if token_mapping[0] == 0 and token_mapping[1] == 0:\n",
    "                 # ignore special token\n",
    "                label.append(-100)\n",
    "            elif token_mapping[1] >= start_char and token_mapping[0] <= end_char:\n",
    "                # in span\n",
    "                label.append(label2id[\"I-E\"])\n",
    "            else:\n",
    "                # outside of span\n",
    "                label.append(label2id[\"O\"])\n",
    "                \n",
    "        labels.append(label)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    tokenized_inputs[\"sample_ids\"] = sample_ids\n",
    "    return tokenized_inputs\n",
    "\n",
    "def tokenize_dataset(dataset):\n",
    "    return dataset.map(\n",
    "        preprocess,\n",
    "        batched=True,\n",
    "        remove_columns=[\"text\",\"target\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653ec7e-70ef-4c25-be1c-0424b439f1bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1184c4-1ad6-477f-b17c-7d1942826873",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099f404e-cb79-4ea6-ba62-bcabd13a48e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import TrainingArguments, Trainer, AutoModelForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72f6c8-0e0e-4c9c-a6a1-f31ab173506e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the metrics for training\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d38f7-dad5-4f93-95d6-9debbeea435b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Login to huggingface to save the model\n",
    "\n",
    "from huggingface_hub import interpreter_login\n",
    "\n",
    "interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36c8130-185e-4716-9e1f-348a0c861683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(dataset, hf_name):\n",
    "    print(f\"Training model {hf_name}\")\n",
    "    \n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        model_checkpoint,\n",
    "        num_labels=2,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        hf_name,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        num_train_epochs=4,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        weight_decay=0.01,\n",
    "        logging_steps=25,\n",
    "        eval_steps=25,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        push_to_hub=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=dataset[\"train\"],\n",
    "        eval_dataset=dataset[\"valid\"],\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.push_to_hub()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bbf4ee-6013-4d4f-ac8a-efc13aa3ccab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the answer extractor\n",
    "\n",
    "dataset_a = make_dataset_split(a_docs)\n",
    "tokenized_dataset_a = tokenize_dataset(dataset_a)\n",
    "train_model(tokenized_dataset_a, config['extract_contents']['HF_ANSWER_MODEL_NAME'])\n",
    "del dataset_a\n",
    "del tokenized_dataset_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2930fd0-2be6-4ccf-896b-8995e8d14e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the question extractor\n",
    "\n",
    "dataset_q = make_dataset_split(q_docs)\n",
    "tokenized_dataset_q = tokenize_dataset(dataset_q)\n",
    "train_model(tokenized_dataset_q, config['extract_contents']['HF_QUESTION_MODEL_NAME'])\n",
    "del dataset_q\n",
    "del tokenized_dataset_q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0acbf60-b3a9-425a-a657-a0ca54b386c3",
   "metadata": {},
   "source": [
    "### Inference\n",
    "You can test inference with your models below. Call the compare(dataset, model, split, index) function to compare the real and predicted answer on the given dataset, model, test/train/valid split, and index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144036a-72d3-4f7c-9717-2e0832156d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "q_checkpoint = config['extract_contents']['HF_QUESTION_MODEL_NAME']\n",
    "a_checkpoint = config['extract_contents']['HF_ANSWER_MODEL_NAME']\n",
    "\n",
    "max_length = 512\n",
    "tokenizer = AutoTokenizer.from_pretrained(q_checkpoint, max_length=max_length, stride = 128, return_overflowing_tokens=True)\n",
    "a_model = pipeline(\"ner\", model=a_checkpoint, tokenizer=tokenizer, aggregation_strategy=\"simple\", stride = 128)\n",
    "q_model = pipeline(\"ner\", model=q_checkpoint, tokenizer=tokenizer, aggregation_strategy=\"simple\", stride = 128)\n",
    "dataset_a = make_dataset_split(a_docs)\n",
    "dataset_q = make_dataset_split(q_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667e654f-90db-4153-99cb-56bc39ba1fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expected_ans(dataset, split, i):\n",
    "    return dataset[split]['text'][i][dataset[split]['target'][i]['start']:dataset[split]['target'][i]['end']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b95a6-8d91-47a8-8e3d-8f576e1692ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predicted_ans(dataset, model, split, i):\n",
    "    text = dataset[split]['text'][i]\n",
    "    tags = model(dataset[split]['text'][i])\n",
    "    max_tags = list(filter(lambda tag: tag['score'] >= .9, tags))\n",
    "    if len(max_tags) == 0 and len(tags) > 0:\n",
    "        max_tags = [max(tags, key=lambda tag: tag['score'])]\n",
    "    if len(max_tags) == 0: \n",
    "        return ''\n",
    "    start_idx = min([tag['start'] for tag in max_tags])\n",
    "    end_idx = max([tag['end'] for tag in max_tags])\n",
    "    \n",
    "    return text[start_idx:end_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5526e0-ec31-4d82-b1e8-03a6872519e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare(dataset, model, split, i):\n",
    "    print(f\"Expected: {expected_ans(dataset, split, i)}\")\n",
    "    print('\\n')\n",
    "    print(f\"Actual: {predicted_ans(dataset, model, split, i)}\")\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0344ee-0b62-4a4d-988e-421b8b40f249",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(dataset_q, q_model, 'test', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff507a3-4971-4ba3-bc72-9584e1911dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare(dataset_a, a_model, 'test', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453c304-5990-4ccd-bcbb-0fde3a9616d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-2.0.0-gpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
