{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85063efe-a64e-4f3a-8278-a523e62f0012",
   "metadata": {},
   "source": [
    "# Unsupervised Clustering of Emails Dataset\n",
    "\n",
    "On the first run, you will need to generate embeddings with a GPU instance. On future runs, set the 'make_embeddings' variable in the cell below to false, and you can use a CPU instance that loads the pre-existing embeddings.\n",
    "\n",
    "When creating embeddings:\n",
    "- Instance: g4dn.xlarge\n",
    "- Image: pytorch 2.0.0 python 3.10 GPU optimized\n",
    "\n",
    "When loading embeddings:\n",
    "- Instance: ml.t3.large\n",
    "- Image: pytorch 2.0.0 python 3.10 CPU optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f69921e-e7a1-4cfd-83f3-68fbfa41895c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_embeddings = False\n",
    "gpu_available = make_embeddings\n",
    "make_clusters = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba65b6-7e75-4223-992e-c93e82bd1964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install notebook ipykernel pandas python-dotenv sentence_transformers accelerate==0.20.3 scikit-learn seaborn bertopic ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac9fdee-e965-41f7-add7-44a95acf7a96",
   "metadata": {},
   "source": [
    "### Load documents / embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21362442-0805-4b5d-89de-41c343d49170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "import pickle\n",
    "import pathlib\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb836b-c73f-4f8d-a58b-fb0a05abb298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "ENCODING = config['global']['ENCODING']\n",
    "in_path = config['make_pairs']['OUT_FILE']\n",
    "out_path_emails = config['cluster_emails']['OUT_FILE_EMAILS']\n",
    "out_path_question_clusters = config['cluster_emails']['OUT_FILE_QUESTION_CLUSTERS']\n",
    "out_path_answer_clusters = config['cluster_emails']['OUT_FILE_ANSWER_CLUSTERS']\n",
    "out_path_model = config['cluster_emails']['OUT_PATH_MODEL']\n",
    "out_path_embeddings = config['cluster_emails']['OUT_PATH_EMBEDDINGS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00913462-98f3-4793-a0f5-cb3333bdf98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def from_csv(in_path):\n",
    "    \"\"\"\n",
    "    Load the emails data\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(in_path, encoding=ENCODING, index_col=False, \n",
    "                              usecols=['conversation','turn','question','answer'])\n",
    "    \n",
    "    questions = np.array(df['question'].tolist())\n",
    "    answers = np.array(df['answer'].tolist())\n",
    "    \n",
    "    combined = []\n",
    "    \n",
    "    for q, a in zip(questions, answers):\n",
    "        combined.append(f'Question: {q}\\n\\nAnswer: {a}');\n",
    "\n",
    "    return questions, answers, np.array(combined)\n",
    "        \n",
    "        \n",
    "questions, answers, combined = from_csv(in_path)\n",
    "texts = {\"questions\": questions, \"answers\": answers, \"combined\": combined}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2429ee69-cf14-47c6-8383-92da05992545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Lists of embeddings\n",
    "embedding_names = ['questions', 'answers', 'combined']\n",
    "embedding_texts = [questions, answers, combined]\n",
    "model_name = \"all-mpnet-base-v2\"\n",
    "\n",
    "def create_embeddings():\n",
    "    # For each embedding, compute the embedding and save to pickle file\n",
    "    embeddings = {}\n",
    "\n",
    "    # Load the base sentence embedding model\n",
    "    device = 'cuda' if gpu_available else 'cpu'\n",
    "    embedding_model = SentenceTransformer(model_name, device=device)\n",
    "\n",
    "    os.makedirs(out_path_embeddings,exist_ok=True)\n",
    "\n",
    "    ### Create dense vectors\n",
    "    for name,content in zip(embedding_names,embedding_texts):\n",
    "        print(f'Computing {name} embeddings')\n",
    "        embeddings[name] = embedding_model.encode(content)\n",
    "\n",
    "        print(f'Saving {name} embeddings to directory')\n",
    "        with open(os.path.join(out_path_embeddings, f'{name}.pkl'), \"wb\") as f:\n",
    "            pickle.dump({'embeddings': embeddings[name]}, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    return embeddings\n",
    "            \n",
    "def load_embeddings():\n",
    "    embeddings = {}\n",
    "    \n",
    "    for file in pathlib.Path(out_path_embeddings).glob('*.pkl'):\n",
    "        with open(file, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            embeddings[file.stem] = data['embeddings']\n",
    "            print(f'Loaded embeddings {file.stem}')\n",
    "            \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d95275-cbe4-460c-896e-2e9d210cbd52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creates or loads embeddings, depending on the options\n",
    "embeddings = None\n",
    "\n",
    "if make_embeddings:\n",
    "    embeddings = create_embeddings()\n",
    "else:\n",
    "    embeddings = load_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09008c4e-6980-49e2-9a5f-15bb994b4b2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cluster documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d12044-ecac-4d93-abf2-fa95b7bc341a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from hdbscan import HDBSCAN\n",
    "import umap.umap_ as umap\n",
    "\n",
    "def cluster_bertopic(texts, embeds):\n",
    "    # Use vectorizer for topic representations that ignores stop words and includes 2-grams\n",
    "    vectorizer_model = CountVectorizer(stop_words=\"english\", min_df=2, ngram_range=(1, 2))\n",
    "    ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "    hdbscan_model = HDBSCAN(min_samples=15, gen_min_span_tree=True, prediction_data=True)\n",
    "\n",
    "    topic_model = BERTopic(vectorizer_model=vectorizer_model, ctfidf_model=ctfidf_model)\n",
    "    topics, probs = topic_model.fit_transform(texts, embeds)\n",
    "    \n",
    "    # Reduce the number of topics to at most 120\n",
    "    topic_model.reduce_topics(texts, nr_topics=120)\n",
    "    topics = topic_model.get_document_info(texts)[\"Topic\"]\n",
    "    topic_model.update_topics(texts, topics=topics)\n",
    "    \n",
    "    # Reduce outliers from HDBSCAN\n",
    "    topics = topic_model.reduce_outliers(texts, topics, strategy=\"embeddings\", embeddings=embeds)\n",
    "    topic_model.outliers_ = 0\n",
    "    \n",
    "    # Update topics after reduction\n",
    "    topic_model.update_topics(texts, topics=topics)\n",
    "    \n",
    "    df = pd.DataFrame(texts, columns =['text'])\n",
    "    df[\"label\"] = topics\n",
    "    return df, topic_model\n",
    "\n",
    "cluster = cluster_bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932edf2e-431e-4c8d-ab71-6eb8bd4a5a63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combine_clusters = None\n",
    "q_clusters = a_clusters = q_model = a_model = c_model = None\n",
    "\n",
    "def save_bertopic_model(model, suffix):\n",
    "    embedding_model = f\"sentence-transformers/{model_name}\"\n",
    "    model.save(os.path.join(out_path_model,suffix), serialization=\"safetensors\", save_ctfidf=True, save_embedding_model=embedding_model)\n",
    "\n",
    "def load_bertopic_model(suffix):\n",
    "    model = BERTopic.load(os.path.join(out_path_model, suffix))\n",
    "    model._outliers = 0\n",
    "    return model\n",
    "\n",
    "if make_clusters:\n",
    "    print(\"Clustering questions\")\n",
    "    q_clusters, q_model = cluster(questions, embeddings[\"questions\"])\n",
    "    print(\"Clustering answers\")\n",
    "    a_clusters, a_model = cluster(answers, embeddings[\"answers\"])\n",
    "    print(\"Clustering combined\")\n",
    "    c_clusters, c_model = cluster(answers, embeddings[\"combined\"])\n",
    "    combine_clusters = pd.merge(q_clusters, a_clusters, left_index=True, right_index=True, suffixes=('_q', '_a'))\n",
    "    combine_clusters[\"label_c\"] = c_clusters[\"label\"]\n",
    "    combine_clusters.to_csv(out_path_emails, encoding=ENCODING)\n",
    "    \n",
    "    # Save the models\n",
    "    save_bertopic_model(q_model, \"q_model_base\")\n",
    "    save_bertopic_model(a_model, \"a_model_base\")\n",
    "    save_bertopic_model(c_model, \"c_model_base\")\n",
    "else:\n",
    "    print(\"Loading emails with precomputed clusters\")\n",
    "    combine_clusters = pd.read_csv(out_path_emails, encoding=ENCODING, index_col = False)\n",
    "    q_model = load_bertopic_model(\"q_model_base\")\n",
    "    a_model = load_bertopic_model(\"a_model_base\")\n",
    "    c_model = load_bertopic_model(\"c_model_base\")\n",
    "    \n",
    "combine_clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba94cf2b-f9ca-4eda-9a2b-44ac098d0053",
   "metadata": {},
   "source": [
    "### Define some utility functions for the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb993501-320c-427e-8975-ff96897c947d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "q_grouped = a_grouped = None\n",
    "\n",
    "def update_topics():\n",
    "    \"\"\"\n",
    "    Updates the df of topics with new topics after a merge\n",
    "    Re-applies stop-word removal to automatic topic names\n",
    "    \"\"\"\n",
    "    global combine_clusters, q_grouped, a_grouped\n",
    "    combine_clusters['label_q'] = q_model.get_document_info(questions)[\"Topic\"]\n",
    "    combine_clusters['label_a'] = a_model.get_document_info(answers)[\"Topic\"]\n",
    "    combine_clusters['label_c'] = c_model.get_document_info(combined)[\"Topic\"]\n",
    "    q_model.update_topics(questions, topics=list(q_model.get_document_info(questions)[\"Topic\"]))\n",
    "    a_model.update_topics(answers, topics=list(a_model.get_document_info(answers)[\"Topic\"]))\n",
    "    c_model.update_topics(combined, topics=list(c_model.get_document_info(combined)[\"Topic\"]))\n",
    "    \n",
    "    q_grouped = combine_clusters.groupby('label_q')\n",
    "    a_grouped = combine_clusters.groupby('label_a')\n",
    "\n",
    "def display_qs(q_cat):\n",
    "    \"\"\"\n",
    "    Displays all questions of the given category\n",
    "    \"\"\"\n",
    "    df_q = q_grouped.get_group(q_cat)\n",
    "    \n",
    "    for text in df_q[\"text_q\"]:\n",
    "        print(\"\\n------------------------------------------------------------\\n\")\n",
    "        print(text.strip())\n",
    "        \n",
    "def display_as(a_cat):\n",
    "    \"\"\"\n",
    "    Displays all answers of the given category\n",
    "    \"\"\"\n",
    "    df_a = a_grouped.get_group(a_cat)\n",
    "    \n",
    "    for text in df_a[\"text_a\"]:\n",
    "        print(\"\\n------------------------------------------------------------\\n\")\n",
    "        print(text.strip())\n",
    "        \n",
    "        \n",
    "def recalc_representative_docs(model, texts):\n",
    "    \"\"\"\n",
    "    Recalculates the representative docs per topic\n",
    "    \"\"\"\n",
    "    documents = pd.DataFrame({\"Document\": texts, \"Topic\": model.topics_, \"Image\": None, \"ID\": range(len(texts))})\n",
    "    model._save_representative_docs(documents)\n",
    "        \n",
    "def clusters_bar_chart(model, fontsize = 12):\n",
    "    \"\"\"\n",
    "    Generates a bar chart of clusters by number of emails\n",
    "    \"\"\"\n",
    "    model._outliers = 0\n",
    "    df = model.get_topic_info()\n",
    "    plt.figure(figsize=(14,8))\n",
    "    plt.bar(df[\"Topic\"], df[\"Count\"])\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Number of Emails')\n",
    "    plt.title('advising@ Emails by Category')\n",
    "    plt.xticks(df[\"Topic\"], df[\"CustomName\"], rotation=45, ha='right', fontsize = fontsize)\n",
    "    plt.savefig('emails_by_category.png', dpi=300, bbox_inches = \"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def hierarchical_chart(model, docs, custom_labels=False):\n",
    "    \"\"\"\n",
    "    Show a hierarchy of clusters for the model\n",
    "    \"\"\"\n",
    "    hierarchical_topics = model.hierarchical_topics(docs)\n",
    "    display(model.visualize_hierarchy(hierarchical_topics=hierarchical_topics, custom_labels=custom_labels))\n",
    "    \n",
    "update_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba64ca-5777-44f8-b564-ce264a80c5d9",
   "metadata": {},
   "source": [
    "### Visualize Question Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8478a505-c26d-4295-b001-30c75ccd77b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca3cdc-1445-4098-8058-df973863b6ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show a dimension-reduced plot of topic similarity\n",
    "q_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a768b53-f27f-4754-a0ae-51fb31536d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hierarchical_chart(q_model,questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a1d9c-cab6-4b6e-8d21-9fe5fb7b8f16",
   "metadata": {},
   "source": [
    "#### Merge question topics\n",
    "Manually merge topics that appear to be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed74efdb-8f27-41f2-b670-976dd42134ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topics_to_merge = [\n",
    "    [49, 46], # internal from other depts\n",
    "    [94, 18], # graduation check, missing requirements for graduation\n",
    "    [56, 26, 86, 36], # grab bag of degree requirements clarifications\n",
    "    [71, 57], # applying for graduation\n",
    "    [63, 81, 34, 72], # degree navigator issues\n",
    "    [114, 15, 45], # credit/d/fail\n",
    "    [48, 88], # EOSC\n",
    "    [76, 80, 115, 87, 107, 29, 110, 51, 42, 100, 14, 65, 4, 73], # requesting help with registration / waitlist\n",
    "    [96], # MATH prerequisites / retake / registration\n",
    "    [1], # failed course / retaking failed course\n",
    "    [102, 84, 93, 5, 117], # transfer credits\n",
    "    [13, 61], # transferring AP / IB credits\n",
    "    [38, 31], # BIOL course prerequisites / requirements\n",
    "    [113, 47, 104], # changing major / specialization\n",
    "    [85, 22, 116], # help with specialization application / options\n",
    "    [82], # honours programs\n",
    "    [33, 10], # full-time status / course load / credit limit\n",
    "    [66, 8], # transferring to faculty of science\n",
    "    [79, 91], # general inquiries about program / degree offerings\n",
    "    [21, 99], # high school / first year physics requirements\n",
    "    [95, 111], # calculus 12 requirement\n",
    "    [41, 44, 60], # requesting appointment / questions about zoom advising\n",
    "    [6, 59, 9], # registration is blocked\n",
    "    [55], # other requests regarding registration\n",
    "    [62, 52, 17], # dropping a course\n",
    "    [77, 24], # academic concession for illness\n",
    "    [118], # other difficult situations requiring advising\n",
    "    [50], # follow-ups and form submissions\n",
    "    [69, 68], # requesting letter / permission / approval\n",
    "    [35], # appeals\n",
    "    [101, 37, 25, 7, 67, 28], # deferred exams\n",
    "    [16, 58], # other academic concessions\n",
    "]\n",
    "\n",
    "q_model.merge_topics(questions, topics_to_merge)\n",
    "update_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57729762-794e-41ce-b4b6-1557ad20bcb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_labels = {\n",
    "    61: \"first year registration webinar\",\n",
    "    60: \"official transcript\",\n",
    "    53: \"GPA rankings / awards\",\n",
    "    63: \"Dean's honour list\",\n",
    "    62: \"diploma 'with distinction'\",\n",
    "    19: \"graduation check / missing graduation requirements\",\n",
    "    30: \"applying for graduation\",\n",
    "    59: \"withdrawing graduation application\",\n",
    "    49: \"minors / credit counting with minors\",\n",
    "    24: \"applying for a minor\",\n",
    "    46: \"dropping a minor\",\n",
    "    58: \"minor course change\",\n",
    "    57: \"academic calendar / degree requirements year version\",\n",
    "    9: \"degree navigator issues\",\n",
    "    15: \"credit / d / fail\",\n",
    "    55: \"checking if course has science credit\",\n",
    "    37: \"arts requirement\",\n",
    "    13: \"communication requirement\",\n",
    "    48: \"breadth requirement\",\n",
    "    32: \"EOSC course / degree issues\",\n",
    "    51: \"MATH prerequisites / retake / registration\",\n",
    "    0: \"requesting help with registration / waitlist\",\n",
    "    6: \"failed a course / retaking a failed course\",\n",
    "    2: \"transfer credits\",\n",
    "    23: \"transferring AP / IB credits\",\n",
    "    17: \"BIOL course prerequisites / requirements\",\n",
    "    36: \"BIOL major requirements\",\n",
    "    22: \"changing major or specialization\",\n",
    "    14: \"help with specialization application / options\",\n",
    "    43: \"honours programs\",\n",
    "    44: \"co-op program\", \n",
    "    56: \"registration date / time\",\n",
    "    1: \"year promotion requirements\", \n",
    "    12: \"full-time status / course load / credit limit\", \n",
    "    33: \"academic leave / time off\", \n",
    "    39: \"readmission\", \n",
    "    29: \"double major / dual degree\", \n",
    "    11: \"major in computer science\", \n",
    "    21: \"general inquiries about program / degree offerings\",\n",
    "    7: \"transferring to faculty of science\", \n",
    "    45: \"second degree program\", \n",
    "    54: \"neurosciene program\", \n",
    "    25: \"high school / first year physics requirements\", \n",
    "    47: \"foundational requirement\", \n",
    "    52: \"calculus 12 requirement\",\n",
    "    16: \"requesting appointment / questions about zoom advising\", \n",
    "    38: \"various registration issues\",\n",
    "    4: \"registration is blocked\", \n",
    "    64: \"distance education\", \n",
    "    34: \"CPSC course requirements\", \n",
    "    8: \"dropping a course\", \n",
    "    10: \"study permits / unable to return to campus\", \n",
    "    31: \"requesting an online exam\", \n",
    "    18: \"academic concessions for illness\",\n",
    "    35: \"withdrawing from UBC\", \n",
    "    26: \"withdrawing from a course\", \n",
    "    40: \"follow-ups / submitting forms\", \n",
    "    28: \"requesting letter / signature / approval\", \n",
    "    41: \"appeals\",\n",
    "    3: \"deferred exams\",\n",
    "    20: \"other academic concessions\",\n",
    "}\n",
    "\n",
    "q_model.set_topic_labels(topic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a8206a-14cf-40b3-8d7f-cc581e081523",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Visualize question topics after merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f643440b-62fe-4305-9bcd-28c5ef437e63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the merged model as well\n",
    "if make_clusters:\n",
    "    save_bertopic_model(q_model, \"q_model_merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf4126b-6feb-4506-8bae-92a4171041e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hierarchical_chart(q_model, questions, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c71df2-f4b7-46f7-ac05-ff2b9b436a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusters_bar_chart(q_model, fontsize = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e71655e-601b-4fac-bc1c-116a679a49e6",
   "metadata": {},
   "source": [
    "#### Apply another merge step\n",
    "There are very many small categories above. To better understand the categories, try applying another merging step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d4c0dc-dd14-4775-b860-08dc248449b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topics_to_merge = [\n",
    "    [60, 53, 63, 62], # \"transcripts, scholarships, rankings\"\n",
    "    [1, 52, 47, 13, 48, 55, 37, 57, 25], # \"faculty of science requirements\"\n",
    "    [34, 6, 51, 17, 36, 32, 11], # \"degree-specific requirements\"\n",
    "    [59, 30, 19], # \"graduation\"\n",
    "    [39, 33, 35], # \"academic leave, withdrawal, and readmission\"\n",
    "    [64, 10], # \"degree logistics, study permits, distance education\",\n",
    "    [31, 3, 20, 18], # \"academic concessions\",\n",
    "    [26, 8, 0, 38, 4, 56], # \"course registration and withdrawal\"\n",
    "    [61, 16, 28, 40, 41], # \"advising appointments and forms\"\n",
    "    [12, 45, 21, 14, 29, 43, 54], # degree options and planning\n",
    "    [49, 24, 46, 58], # minors\n",
    "    [42, 50, 5, 27], # \"uncategorized\"\n",
    "    [44], # \"co-op\"\n",
    "    [23, 7, 2, 22], # \"transferring and transfer credits\"\n",
    "    [9], # \"issues with degree navigator\"\n",
    "    [15], # \"credit/d/fail\"\n",
    "]\n",
    "\n",
    "q_model.merge_topics(questions, topics_to_merge)\n",
    "update_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c0bbe9-c17e-4617-a153-c73d526f7479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_labels = {\n",
    "    14: \"transcripts, scholarships, rankings\",\n",
    "    1: \"faculty of science requirements\",\n",
    "    3: \"degree-specific requirements\",\n",
    "    8: \"graduation\",\n",
    "    12: \"academic leave, withdrawal, and readmission\",\n",
    "    9: \"degree logistics, study permits, distance education\",\n",
    "    4: \"academic concessions\",\n",
    "    0: \"course registration and withdrawal\",\n",
    "    7: \"advising appointments, forms, and appeals\",\n",
    "    5: \"degree options and planning\",\n",
    "    11: \"minors\",\n",
    "    6: \"uncategorized\",\n",
    "    15: \"co-op\",\n",
    "    2: \"transferring and transfer credits\",\n",
    "    10: \"issues with degree navigator\",\n",
    "    13: \"credit/d/fail\",\n",
    "}\n",
    "\n",
    "q_model.set_topic_labels(topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d59526-df02-4924-864d-031f09b7749c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_clusters:\n",
    "    save_bertopic_model(q_model, \"q_model_merged_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9898f8-4fba-4dda-934d-b038cdaee5a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hierarchical_chart(q_model, questions, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce9f051-f2b4-447c-acad-ac230b68f8d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusters_bar_chart(q_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94008d1e-96fe-430f-a201-6e52b62dd99b",
   "metadata": {},
   "source": [
    "## Evaluate answer categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ace14c-24b3-415f-8d27-69539c5e01c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de6fa6e-fcaf-4d10-af14-50a822a7fef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hierarchical_chart(a_model, answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35b85b9-53d2-4287-952d-36287617c78e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Merge answer categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f7638-a1db-4703-bb78-7b51b469b1bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topics_to_merge = [\n",
    "    [14, 15], # drop-in\n",
    "    [81, 20], # applying for a minor\n",
    "    [6, 4], # specialization application\n",
    "    [74, 59, 7], # specific to degree-navigator\n",
    "    [93, 61], # alternate format assessment\n",
    "    [5, 10], # deferred exams\n",
    "    [53, 30, 29, 32], # course withdrawal requests\n",
    "    [84, 97], # course mode of delivery\n",
    "    [50, 43], # credit limits\n",
    "    [45, 18, 25], # graduation application / eligibility\n",
    "    [57], # off-cycle promotion\n",
    "    [49, 35, 33, 51, 41], # administrative, undergoing review, acknowledging receipt, etc.\n",
    "    [88, 63, 77, 36], # eligibilities, sessional eval, year standing\n",
    "    [54, 19], # registration dates and blocked registration\n",
    "    [62, 8], # concessions and registration issues for CHEM courses\n",
    "    [55, 28, 11, 13, 24, 67, 26, 69, 39, 38], # help with registration\n",
    "    [37, 66], # credit specifics and requirement replacements\n",
    "    [89, 98], # calculus 12 requirement\n",
    "    [85, 82, 87], # refer to enrolment services\n",
    "    [95, 90, 96], # refer to another faculty\n",
    "    [71, 46], # registration webinar\n",
    "    [14, 15], # resolved in drop-in\n",
    "]\n",
    "\n",
    "a_model.merge_topics(answers, topics_to_merge)\n",
    "update_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240df8b-93a4-42dc-bde9-fe25c8438aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_labels = {\n",
    "    34 : \"removed from minor\", # 47\n",
    "    16 : \"applying for a minor\", # 81\n",
    "    40 : \"minor course change form\", # 58 \n",
    "    49 : \"not permitted to repeat course for higher standing\", # 73\n",
    "    22 : \"first year phys requirements\", # 23\n",
    "    18 : \"upper-level credit requirements\", # 16\n",
    "    5 : \"questions about BIOL courses\", #2\n",
    "    2 : \"specialization application\", # 6\n",
    "    4 : \"promotion requirements\", # 1\n",
    "    14 : \"communication requirement\", # 12\n",
    "    6 : \"transfer credit\", # 3\n",
    "    1 : \"transferring faculty / admission\", # 0\n",
    "    26 : \"second degree\", # 31\n",
    "    36 : \"neuroscience program\", # 52\n",
    "    35 : \"arts requirement\", # 48\n",
    "    24 : \"credit specifics and requirement replacements\", # 37\n",
    "    11 : \"degree navigator specifics\",\n",
    "    33 : \"alternate format assessment\",\n",
    "    3 : \"deferred exam request\",\n",
    "    25 : \"academic concessions\", # 27\n",
    "    8 : \"course drop/withdrawal request\", # 53\n",
    "    43 : \"course conflict form\", # 65\n",
    "    45 : \"switching course section\", # 68\n",
    "    44 : \"course mode of delivery\", # 84\n",
    "    23 : \"credit limits\", \n",
    "    42 : \"appeal for third attempt\", # 64\n",
    "    58 : \"appeal received\", # 91\n",
    "    50 : \"honours appeal\", # 76\n",
    "    32 : \"honours requirements\", # 44\n",
    "    56 : \"rankings, honour list, distinction\", # 86\n",
    "    7 : \"graduation application / eligibility\", #\n",
    "    38 : \"off-cycle promotion\",\n",
    "    9 : \"administrative, undergoing review, acknowledging receipt, etc.\",\n",
    "    21 : \"credit/d/fail\", # 22\n",
    "    59 : \"CMS packages / requirements\", # 94\n",
    "    17 : \"eligibilities, sessional eval, year standing\",\n",
    "    15 : \"registration dates and blocked registration\", \n",
    "    0 : \"help with registration\",\n",
    "    46 : \"calculus 12 requirement\",\n",
    "    30 : \"refer to enrolment services\",\n",
    "    37 : \"refer to another faculty\", # 95, 90, 96\n",
    "    48 : \"advice for failed course\", # 72\n",
    "    28 : \"changing specializtion\", # 34\n",
    "    39 : \"admission averages\", # 56\n",
    "    31 : \"readmission\", # 42\n",
    "    13 : \"academic leave / inability to return to campus\", # 9\n",
    "    19 : \"refer to counselling services\", # 17\n",
    "    20 : \"appointments / virtual lines\", # 21\n",
    "    27 : \"distillation emails / registration webinars\", # 71\n",
    "    55 : \"go global\", # 83\n",
    "    52 : \"co-op\", # 80\n",
    "    57 : \"course load for full-time status\", # 92\n",
    "    54 : \"requsting a letter\", # 79\n",
    "    47 : \"requesting student number\", # 70\n",
    "    41 : \"refer to another departent / faculty\", # 60\n",
    "    51 : \"refer to arts advising\", # 75\n",
    "    53 : \"refer to UBC-O advising\", # 78\n",
    "    10 : \"resolved in drop-in\",\n",
    "    12 : \"concessions and registration issues for CHEM courses\",\n",
    "    29 : \"double / dual major\"\n",
    "}\n",
    "\n",
    "a_model.set_topic_labels(topic_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2381a632-532e-4f36-92a5-b42fe866ba2c",
   "metadata": {},
   "source": [
    "#### Visualize answer topics after merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dedf6e-a42e-4d63-8572-21b2c5e1e781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if make_clusters:\n",
    "    save_bertopic_model(q_model, \"a_model_merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b7360-71d5-4dd6-8c7e-ffadcc9e4289",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hierarchical_chart(a_model, answers, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c728b772-caf1-4c82-bce0-2e2e19fb3f31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusters_bar_chart(a_model, fontsize=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0576b-0ea4-42e4-b76e-3b9858c96454",
   "metadata": {},
   "source": [
    "## Calculate Correlation\n",
    "Now that we have created the question and answer categories, we want to see how well they line up. What is the correlation between a question category and an answer category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45b1e0-f58e-4830-b87b-efa4872c09fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the questions model from the first merge step\n",
    "q_model = load_bertopic_model(\"q_model_merged\")\n",
    "update_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74744e99-926a-4f05-ace4-7f02f72a6a52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\"\"\"\n",
    "Convert the categorical labels label_q and label_a in the df to onehot features,\n",
    "then make a correlation matrix between all label_q and label_a classes\n",
    "\"\"\"\n",
    "def make_onehot_corr_df(df):\n",
    "    \"\"\"\n",
    "    Convert the categorical labels label_q and label_a in the df to onehot features,\n",
    "    then make a correlation matrix between all label_q and label_a classes\n",
    "    \"\"\"\n",
    "    # onehot-encode the labels\n",
    "    one_hot_feats = [\"label_q\", \"label_a\"]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"onehot\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"), one_hot_feats),\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    preprocessor.set_output(transform=\"pandas\")\n",
    "\n",
    "    onehot = preprocessor.fit_transform(df)\n",
    "    \n",
    "    # compute correlation and remove irrelevant columns\n",
    "    onehot_corr = onehot.corr(numeric_only = True)\n",
    "    a_cols = [col for col in onehot_corr.columns if 'label_a' in col]\n",
    "    q_cols = [col for col in onehot_corr.columns if 'label_q' in col]\n",
    "    onehot_corr = onehot_corr[a_cols]\n",
    "    onehot_corr = onehot_corr.loc[q_cols]\n",
    "    \n",
    "    return onehot_corr\n",
    "\n",
    "onehot_corr = make_onehot_corr_df(combine_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcba6776-2841-4df6-91d6-752a1c768476",
   "metadata": {},
   "source": [
    "Plot the correlation matrix for any correlations over a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7283f9e7-e93a-495d-bda2-b388ccde4d77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "threshold = 0.3\n",
    "onehot_corr_filtered = onehot_corr[onehot_corr >= threshold]\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(onehot_corr_filtered, cmap=\"Greens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec16c857-2323-479f-8ec5-37686535b9f5",
   "metadata": {},
   "source": [
    "### Create a summary of categories\n",
    "We will create some summary files to give more insight into the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3607ba9a-7edf-400d-8d71-2c7270e2fa76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "pairs_df = None\n",
    "\n",
    "\"\"\"\n",
    "Convert a row name from the onehot df to class id\n",
    "\"\"\"\n",
    "def rn_to_id(row_name):\n",
    "    return int(re.search(\"\\-?\\d+\", row_name).group())\n",
    "\n",
    "\"\"\"\n",
    "Pair each question category with the best answer category\n",
    "\"\"\"\n",
    "def find_best_corr_pairs(corr):            \n",
    "    pairs = []\n",
    "    \n",
    "    for i, col_name in enumerate(corr.idxmax(axis=1)):\n",
    "        row_name = corr.index[i]\n",
    "        pairs.append((rn_to_id(row_name), rn_to_id(col_name), corr.loc[row_name, col_name]))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "\"\"\"\n",
    "Initialize a df summarizing question categories\n",
    "\"\"\"\n",
    "def init_qs_df():\n",
    "    pairs = find_best_corr_pairs(onehot_corr)\n",
    "\n",
    "    cat_pairs = []\n",
    "    \n",
    "    q_topic_df = q_model.get_topic_info()\n",
    "\n",
    "    for q_cat, a_cat, corr in pairs:\n",
    "        q_df = q_grouped.get_group(q_cat)\n",
    "        fraction_matching_a = len(q_df[q_df[\"label_a\"] == a_cat]) / len(q_df)\n",
    "        a_label = a_model.custom_labels_[a_cat]\n",
    "        cat_pairs.append({\"q_cat\": q_cat, \n",
    "                          \"q_label\": q_topic_df.iloc[q_cat][\"CustomName\"],\n",
    "                          \"a_cat\": a_cat, \n",
    "                          \"a_label\": a_label,\n",
    "                            \"n_q\": len(q_df), \n",
    "                          \"fraction_q_with_a\": fraction_matching_a, \n",
    "                          \"corr\": corr,\n",
    "                          \"sample_docs\": q_topic_df.iloc[q_cat][\"Representative_Docs\"]})\n",
    "\n",
    "    return pd.DataFrame(cat_pairs)\n",
    "    \n",
    "\"\"\"\n",
    "Initialize a df summarizing answer categories\n",
    "\"\"\"\n",
    "def init_as_df():\n",
    "    a_topic_df = a_model.get_topic_info()\n",
    "    \n",
    "    rows = []\n",
    "\n",
    "    for a_cat in a_topic_df[\"Topic\"]:\n",
    "        a_df = a_grouped.get_group(a_cat)\n",
    "        rows.append({\"a_cat\": a_cat,\n",
    "                     \"a_label\": a_topic_df.iloc[a_cat][\"CustomName\"],\n",
    "                     \"n_a\": len(a_df),\n",
    "                     \"sample_docs\": a_topic_df.iloc[a_cat][\"Representative_Docs\"]})\n",
    "\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "    \n",
    "\"\"\"\n",
    "Scores the correlations by weighted average of best correlation by number of questions\n",
    "\"\"\"\n",
    "def score_corr(qs_df):\n",
    "    return np.average(qs_df[\"corr\"], weights=qs_df[\"n_q\"])\n",
    "    \n",
    "def save_df(df, name):\n",
    "    df.to_csv(name, encoding=ENCODING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeebfda8-9765-4be6-b205-2322c59be982",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qs_df = init_qs_df()\n",
    "as_df = init_as_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b8164-daa6-4f2e-a284-6b311187dd4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "as_df = pd.read_csv(\"answer_categories.csv\", encoding=ENCODING, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a74accc-5abc-4af0-96ab-e2d803776674",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qs_df = pd.read_csv(\"question_categories.csv\", encoding=ENCODING, index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef005fb-fc87-4a51-94ce-f0fee9f300ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bb4c7c-9a12-4f8e-a449-532ccaba55e2",
   "metadata": {},
   "source": [
    "We can calculate the weighted average of correlations per category for an overall metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab60b51-18d6-437c-9206-04d61d267283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_corr(qs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2c1d7e-2fc2-4284-abd2-a8be0ab0bc5a",
   "metadata": {},
   "source": [
    "## Category analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0642987c-5ce3-4514-ba51-d5968c004310",
   "metadata": {},
   "source": [
    "Collect the most common urls from each answer category, and add them to the summary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b9318-a4a6-47f2-ac73-8a2d7e7daa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import requests\n",
    "\n",
    "# url regex from https://www.geeksforgeeks.org/python-check-url-string/\n",
    "URL_REGEX = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "\n",
    "def find_most_common_links(cats_df, by_q = True):\n",
    "    \"\"\"\n",
    "    Finds the most common links in the answers for a given category\n",
    "    Can group by a question category or an answer category\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, cat in enumerate(cats_df[\"q_cat\" if by_q else \"a_cat\"]):\n",
    "        # regex match every url mentioned in the answers of this category\n",
    "        group_df = q_grouped.get_group(cat) if by_q else a_grouped.get_group(cat)\n",
    "        urls = list(group_df[\"text_a\"].str.extractall(URL_REGEX)[0])\n",
    "        \n",
    "        # resolve redirects and find most common urls\n",
    "        final_counts = {}\n",
    "\n",
    "        for url, count in Counter(urls).most_common(20):\n",
    "            url = url if url.startswith('http') else ('http://' + url)\n",
    "            try:\n",
    "                r = requests.get(url)\n",
    "            except:\n",
    "                # ignore invalid url\n",
    "                continue\n",
    "                \n",
    "            if r.url in final_counts:\n",
    "                final_counts[r.url] += count\n",
    "            else:\n",
    "                final_counts[r.url] = count\n",
    "            \n",
    "        cats_df.loc[cats_df.index[i], \"common_urls\"] = [Counter(final_counts).most_common(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c55e7-1b1b-4bb7-8795-0633caec852c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "find_most_common_links(as_df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc6cfda-7415-4b7d-96a2-80e106025d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "find_most_common_links(qs_df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bcd443-4feb-4016-be00-d8e94660aa53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the summary files\n",
    "save_df(as_df, out_path_answer_clusters)\n",
    "save_df(qs_df, out_path_question_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80350559-8d42-4f1b-8080-c2b63d25c1af",
   "metadata": {},
   "source": [
    "### Use an LLM to generate an FAQ\n",
    "This is an experimental section, and it didn't generate very promising results at the moment, but could be improved. The idea is to use the representative documents for a topic and pass them through an LLM to generate an FAQ for each question category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64fdaea-59d1-46c4-a70b-35f2216b795e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install langchain boto3 tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc7e2be-f648-431b-afd1-afbabf6013ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from typing import Dict\n",
    "import json\n",
    "\n",
    "endpoint_name = \"meta-textgeneration-llama-2-7b-f-2023-10-29-21-47-29-374\"\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        payload = {\n",
    "            \"inputs\": [\n",
    "                [\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "                ],\n",
    "                \"parameters\": {\"max_new_tokens\": 1000, \"top_p\": 0.6, \"temperature\": 0.1},\n",
    "        }\n",
    "\n",
    "        input_str = json.dumps(\n",
    "            payload,\n",
    "        )\n",
    "        \n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        content = response_json[0][\"generation\"][\"content\"]\n",
    "        return content\n",
    "\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "\n",
    "llm=SagemakerEndpoint(\n",
    "    endpoint_name=endpoint_name,\n",
    "    #credentials_profile_name=\"credentials-profile-name\",\n",
    "    region_name=\"us-west-2\",\n",
    "    model_kwargs={\"temperature\": 1e-10},\n",
    "    endpoint_kwargs={\"CustomAttributes\": 'accept_eula=true'},\n",
    "    content_handler=content_handler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ca558-2c6d-47c1-a957-7fafeabd59fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain, LLMChain, StuffDocumentsChain\n",
    "\n",
    "# https://python.langchain.com/docs/use_cases/summarization\n",
    "max_samples = 10\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "\n",
    "map_prompt_template = \"\"\"\n",
    "                      Summarize the following text contains one or more questions and answers. Write the key questions and their corresponding answers as bullet points in the following format:\n",
    "                      - Q: ...\n",
    "                        A: ...\n",
    "                      - Q: ...\n",
    "                        A: ...\n",
    "                      Do not include any other text.\n",
    "                      TEXT:\n",
    "                      {text}\n",
    "                      \"\"\"\n",
    "\n",
    "map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "combine_prompt_template = \"\"\"\n",
    "                      Write a concise FAQ from the following list of questions and answers.\n",
    "                      Combine similar questions into one bullet point, and ignore questions about a particular student / course / year.\n",
    "                      Return your response in bullet points which covers the most common general questions and answers in the following format:\n",
    "                      - Q: ...\n",
    "                        A: ...\n",
    "                      - Q: ...\n",
    "                        A: ...\n",
    "                      ```{text}```\n",
    "                      BULLET POINT SUMMARY:\n",
    "                      \"\"\"\n",
    "\n",
    "combine_prompt = PromptTemplate(\n",
    "    template=combine_prompt_template, input_variables=[\"text\"]\n",
    ")\n",
    "\n",
    "map_reduce_chain = load_summarize_chain(\n",
    "    llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    map_prompt=map_prompt,\n",
    "    combine_prompt=combine_prompt,\n",
    "    return_intermediate_steps=False,\n",
    ")\n",
    "\n",
    "def summarize_category(q_cat, a_cat):\n",
    "    q_df = q_grouped.get_group(q_cat)\n",
    "    qa_df = q_df.groupby(\"label_a\").get_group(a_cat)\n",
    "    \n",
    "    sample = qa_df.sample(max_samples)\n",
    "    \n",
    "    sample_texts = []\n",
    "        \n",
    "    for q, a in zip(sample[\"text_q\"], sample[\"text_a\"]):\n",
    "        sample_texts.append(f\"Question: {q}\\n\\nAnswer: {a}\")\n",
    "    \n",
    "    docs = [Document(page_content=text) for text in sample_texts]\n",
    "                    \n",
    "    return map_reduce_chain.run(docs)\n",
    "\n",
    "def make_summaries(qs_df):\n",
    "    for i, (q_cat, a_cat) in enumerate(zip(qs_df[\"q_cat\"], qs_df[\"a_cat\"])):\n",
    "        summary = summarize_category(q_cat, a_cat)\n",
    "        print(summary)\n",
    "    \n",
    "        qs_df.loc[pairs_df.index[i], \"summary\"] = summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9301c2b2-cef6-4038-981d-737140556768",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_summaries(qs_df[0:1])"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.large",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-2.0.0-cpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
